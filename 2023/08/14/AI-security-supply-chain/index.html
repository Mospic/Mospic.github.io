<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no"><meta name="author" content="Mospic"><meta name="renderer" content="webkit"><meta name="copyright" content="Mospic"><meta name="keywords" content="Mospic"><meta name="description" content=""><meta name="Cache-Control" content="no-cache"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><title>AI-security-supply-chain · Mospic's Blog</title><link rel="stylesheet" href="/css/style.css?v=2018.7.9"><link rel="stylesheet" href="/css/animation.css?v=2018.7.9"><link rel="icon" href="/img/assets/favicon.ico"><link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css?version=1.5.6"><!-- scripts--><script>(function( w ){
  "use strict";
  // rel=preload support test
  if( !w.loadCSS ){
    w.loadCSS = function(){};
  }
  // define on the loadCSS obj
  var rp = loadCSS.relpreload = {};
  // rel=preload feature support test
  // runs once and returns a function for compat purposes
  rp.support = (function(){
    var ret;
    try {
      ret = w.document.createElement( "link" ).relList.supports( "preload" );
    } catch (e) {
      ret = false;
    }
    return function(){
      return ret;
    };
  })();

  // if preload isn't supported, get an asynchronous load by using a non-matching media attribute
  // then change that media back to its intended value on load
  rp.bindMediaToggle = function( link ){
    // remember existing media attr for ultimate state, or default to 'all'
    var finalMedia = link.media || "all";

    function enableStylesheet(){
      link.media = finalMedia;
    }

    // bind load handlers to enable media
    if( link.addEventListener ){
      link.addEventListener( "load", enableStylesheet );
    } else if( link.attachEvent ){
      link.attachEvent( "onload", enableStylesheet );
    }

    // Set rel and non-applicable media type to start an async request
    // note: timeout allows this to happen async to let rendering continue in IE
    setTimeout(function(){
      link.rel = "stylesheet";
      link.media = "only x";
    });
    // also enable media after 3 seconds,
    // which will catch very old browsers (android 2.x, old firefox) that don't support onload on link
    setTimeout( enableStylesheet, 3000 );
  };

  // loop through link elements in DOM
  rp.poly = function(){
    // double check this to prevent external calls from running
    if( rp.support() ){
      return;
    }
    var links = w.document.getElementsByTagName( "link" );
    for( var i = 0; i < links.length; i++ ){
      var link = links[ i ];
      // qualify links to those with rel=preload and as=style attrs
      if( link.rel === "preload" && link.getAttribute( "as" ) === "style" && !link.getAttribute( "data-loadcss" ) ){
        // prevent rerunning on link
        link.setAttribute( "data-loadcss", true );
        // bind listeners to toggle media back
        rp.bindMediaToggle( link );
      }
    }
  };

  // if unsupported, run the polyfill
  if( !rp.support() ){
    // run once at least
    rp.poly();

    // rerun poly on an interval until onload
    var run = w.setInterval( rp.poly, 500 );
    if( w.addEventListener ){
      w.addEventListener( "load", function(){
        rp.poly();
        w.clearInterval( run );
      } );
    } else if( w.attachEvent ){
      w.attachEvent( "onload", function(){
        rp.poly();
        w.clearInterval( run );
      } );
    }
  }


  // commonjs
  if( typeof exports !== "undefined" ){
    exports.loadCSS = loadCSS;
  }
  else {
    w.loadCSS = loadCSS;
  }
}( typeof global !== "undefined" ? global : this ) );</script><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js" defer></script><script src="/js/main.js?v=2018.7.9" defer></script><!-- fancybox--><link rel="preload" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" defer></script><!-- busuanzi--><script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><meta name="generator" content="Hexo 6.3.0"></head><body><section class="profile-close" id="cxo-profile"><div class="profile-avatar"><i class="fa fa-caret-left"></i><img src="/img/assets/venti.jpg"></div><!--.profile-saying
  i.fa.fa-comment
  .saying--><div class="cxo-profile-inner"><div class="profile-name">Mospic</div><div class="profile-signature">这里是Mospic的小博客</div><div class="read-progress"></div></div></section><header id="cxo-intro" style="height: 70vh;background-image: url(/img/intro/index-bg.png);"><nav id="cxo-intro-nav"><section><div class="intro-nav-title"><a href="/">Mospic's Blog</a></div><div class="intro-nav-label-box"><a href="/">Home</a><a href="/about/">About</a><a href="/archives/">Archives</a><a href="/tags/">Tags</a></div><i class="fa fa-bars intro-nav-menu"><div class="intro-nav-drop"><a href="/">Home</a><a href="/about/">About</a><a href="/archives/">Archives</a><a href="/tags/">Tags</a></div></i><div class="clear"></div></section></nav><h1 class="post-title">AI-security-supply-chain</h1><div class="post-intros"><div class="post-intro-meta"><span class="post-intro-time"><i class="post-intro-calendar fa fa-calendar"></i><span>2023-08-14</span></span></div></div></header><article class="cxo-up" id="cxo-content-outer"><section id="cxo-content-inner"><article class="article-entry" id="post"><h1 id="AI软件供应链安全"><a href="#AI软件供应链安全" class="headerlink" title="AI软件供应链安全"></a>AI软件供应链安全</h1><h2 id="软件供应链"><a href="#软件供应链" class="headerlink" title="软件供应链"></a>软件供应链</h2><ul>
<li>Q1：什么是软件供应链？</li>
</ul>
<p><strong>软件供应链</strong>（英语：software supply chain）是将<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%A3%BD%E9%80%A0%E6%A5%AD">制造业</a>的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%BE%9B%E6%87%89%E9%8F%88">供应链</a>概念用在<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%BB%9F%E4%BB%B6%E9%96%8B%E7%99%BC">软件开发</a>上，是指在<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%88%B6%E5%93%81">软件制品</a>（software artifact）开发过程中，所需要的元件（component）、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%87%BD%E5%BC%8F%E5%BA%AB">函式库</a>、工具和流程[<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/zh-cn/%E8%BB%9F%E9%AB%94%E4%BE%9B%E6%87%89%E9%8F%88#cite_note-1">1]</a>。（Wikipedia）</p>
<p>两个Survey</p>
<p> [For Good Measure Counting Broken Links A Quant’s View of Software Supply Chain Security.pdf（USENIX; Login, 2020）](For Good Measure Counting Broken Links A Quant’s View of Software Supply Chain Security.pdf) </p>
<p><a target="_blank" rel="noopener" href="https://d.wanfangdata.com.cn/periodical/ChhQZXJpb2RpY2FsQ0hJTmV3MjAyMzA4MDYSDXJqeGIyMDIzMDMwMTgaCDViN3F2ZzF5"><strong>开源软件供应链安全研究综述（软件学报2023）</strong></a></p>
<h2 id="AI软件重用威胁"><a href="#AI软件重用威胁" class="headerlink" title="AI软件重用威胁"></a>AI软件重用威胁</h2><h3 id="Model-Reuse-Attacks-on-Deep-Learning-Systems（Proceedings-of-the-2018-ACM-SIGSAC-conference-on-computer-and-communications-…-2018）"><a href="#Model-Reuse-Attacks-on-Deep-Learning-Systems（Proceedings-of-the-2018-ACM-SIGSAC-conference-on-computer-and-communications-…-2018）" class="headerlink" title="Model-Reuse Attacks on Deep Learning Systems（Proceedings of the 2018 ACM SIGSAC conference on computer and communications …, 2018）"></a>Model-Reuse Attacks on Deep Learning Systems（Proceedings of the 2018 ACM SIGSAC conference on computer and communications …, 2018）</h3><ul>
<li>本文研究了深度学习系统中的模型重用攻击，通过实证研究展示了恶意模型对机器学习系统的巨大威胁，并提出了一种广泛适用的攻击方法。</li>
</ul>
<h4 id="背景信息"><a href="#背景信息" class="headerlink" title="背景信息:"></a>背景信息:</h4><ul>
<li>论文背景: 当前的机器学习系统通常通过重用多个原始模型来构建，这些模型往往由不可信的来源贡献和维护，缺乏标准化和监管，因此存在严重的安全隐患。</li>
<li>过去方案: 过去的研究主要关注软件开发中外部模块的安全风险，而对于将原始模型作为机器学习系统构建块的安全风险知之甚少。</li>
<li>论文的Motivation: 鉴于原始模型在许多安全关键领域的广泛应用，本文旨在填补这一研究空白，研究恶意原始模型对机器学习系统安全的潜在威胁。</li>
</ul>
<h4 id="原始模型在GitHub中的重用"><a href="#原始模型在GitHub中的重用" class="headerlink" title="原始模型在GitHub中的重用"></a>原始模型在GitHub中的重用</h4><p><img src="/.io//image-20230812223406982.png" alt="image-20230812223406982"></p>
<h4 id="重用可能造成的攻击影响"><a href="#重用可能造成的攻击影响" class="headerlink" title="重用可能造成的攻击影响"></a>重用可能造成的攻击影响</h4><ul>
<li>Infecting ML Systems</li>
<li>Crafting Adversarial Models</li>
</ul>
<h4 id="后面搞了一堆公式和算法"><a href="#后面搞了一堆公式和算法" class="headerlink" title="后面搞了一堆公式和算法"></a>后面搞了一堆公式和算法</h4><h2 id="An-Empirical-Study-of-Pre-Trained-Model-Reuse-in-the-Hugging-Face-Deep-Learning-Model-Registry（arXiv-preprint-arXiv-2303-02552-2023）"><a href="#An-Empirical-Study-of-Pre-Trained-Model-Reuse-in-the-Hugging-Face-Deep-Learning-Model-Registry（arXiv-preprint-arXiv-2303-02552-2023）" class="headerlink" title="An Empirical Study of Pre-Trained Model Reuse in the Hugging Face Deep Learning Model Registry（arXiv preprint arXiv:2303.02552, 2023）"></a>An Empirical Study of Pre-Trained Model Reuse in the Hugging Face Deep Learning Model Registry（arXiv preprint arXiv:2303.02552, 2023）</h2><p>Huggingface 是一个开源的nlp框架，提供了多种预训练模型和数据集，让你快速用科研大牛的模型进行nlp任务。</p>
<h3 id="论文简要"><a href="#论文简要" class="headerlink" title="论文简要 :"></a>论文简要 :</h3><ul>
<li>本研究通过对Hugging Face深度学习模型注册表的实证研究，探讨了预训练模型重用的实践和挑战，提出了模型重用的决策过程和有用属性，并测量了模型重用面临的挑战和风险。</li>
</ul>
<h3 id="背景信息-1"><a href="#背景信息-1" class="headerlink" title="背景信息:"></a>背景信息:</h3><ul>
<li>论文背景: 深度神经网络(DNNs)作为软件系统的组成部分被广泛采用，但从头开始创建和专门化DNNs变得越来越困难。为了解决这个问题，机器学习工程师开始重用大规模的预训练模型(PTMs)并对其进行微调以适应下游任务。然而，我们缺乏关于PTM重用的指导性知识，以指导PTM生态系统中的行为。</li>
<li>过去方案: 之前的研究主要关注传统软件包的重用实践，缺乏对PTM包重用的研究。</li>
<li>论文的Motivation: 本研究旨在填补PTM重用领域的知识空白，通过对Hugging Face深度学习模型注册表的实证研究，探索PTM重用的实践和挑战，并提供有用的属性和决策过程，以指导未来的深度学习生态系统优化和模型注册表的基础设施和标准化研究。</li>
</ul>
<h3 id="意义"><a href="#意义" class="headerlink" title="意义:"></a>意义:</h3><p>PTM的重用降低了在工业中使用dnn的工程成本。本文从软件工程的角度描述了对PTM重用的首次研究。我们是第一个(1)捕获决策制定工作流和PTM重用挑战的人;(2)确定便于重用的ptm属性;(3)在Hugging Face DL模型注册表中度量PTM重用的风险。我们的发现可以帮助PTM维护者和注册中心提高其产品的质量，并显示软件工程工具在此过程中支持PTM重用者的机会。</p>
<p><img src="/.io//image-20230813115128977.png" alt="image-20230813115128977"></p>
<h3 id="关注PTM重用："><a href="#关注PTM重用：" class="headerlink" title="关注PTM重用："></a>关注PTM重用：</h3><ul>
<li>RQ1 How do engineers select PTMs?</li>
<li>RQ2 What PTM attributes facilitate PTM reuse?</li>
<li><strong>RQ3 What are the challenges of PTM reuse?</strong>     在文章的P6</li>
</ul>
<p>Almost every participant mentioned that there are missing details in the model registries,including datasets, licensing, model details, robustness, and interpretability.</p>
<ul>
<li>RQ4 To what extent are the risks of reusing PTMs mitigated by Hugging Face defenses?</li>
</ul>
<h2 id="Reusing-Deep-Learning-Models-Challenges-and-Directions-in-Software-Engineering（arXiv-preprint-arXiv-2303-07476-2023）"><a href="#Reusing-Deep-Learning-Models-Challenges-and-Directions-in-Software-Engineering（arXiv-preprint-arXiv-2303-07476-2023）" class="headerlink" title="Reusing Deep Learning Models: Challenges and Directions in Software Engineering（arXiv preprint arXiv:2303.07476, 2023）"></a>Reusing Deep Learning Models: Challenges and Directions in Software Engineering（arXiv preprint arXiv:2303.07476, 2023）</h2><h3 id="论文简要-1"><a href="#论文简要-1" class="headerlink" title="论文简要 :"></a>论文简要 :</h3><ul>
<li>本文探讨了在软件工程中重用深度神经网络（DNN）的挑战和未来方向，总结了现有的重用技术研究，并提出了改进每种重用类型的可能方法。</li>
</ul>
<h3 id="背景信息-2"><a href="#背景信息-2" class="headerlink" title="背景信息:"></a>背景信息:</h3><ul>
<li>论文背景: 本文介绍了深度学习在计算机视觉、系统配置和问答等领域取得的最先进性能，以及深度学习进入软件工程领域的重要性。</li>
<li>过去方案: 传统软件工程中的软件重用已经得到了广泛研究，但对于深度学习软件的重用研究还处于初级阶段。</li>
<li>论文的Motivation: 由于深度学习模型的开发成本高昂，包括知识性工作和计算成本，因此在公司内部和整个计算行业中重用深度学习模型是一种有前景的方向。然而，深度学习模型的重用面临着许多挑战，包括技术能力和工程实践的缺失。本文旨在描述当前深度学习模型重用方法中的挑战，并提出改进每种重用类型的可能方法。</li>
</ul>
<h3 id="方法"><a href="#方法" class="headerlink" title="方法:"></a>方法:</h3><ul>
<li>a. 理论背景:<ul>
<li>本文讨论了在软件工程中重复使用深度神经网络（DNNs）所面临的挑战和未来方向。它强调了开发DNNs的高成本以及重复使用它们的潜在好处。作者承认在重复使用DNNs方面存在技术能力和工程实践方面的挑战。本文旨在总结关于重复使用DNNs的研究，并概述改进每种重复使用类型的可能进展。</li>
</ul>
</li>
<li>b. 技术路线:<ul>
<li>本文提供了工程深度神经网络（DNNs）的概述。它解释了DNN的组成部分，包括DNN模型、数据管道和训练机制。DNN模型是一个由加权操作组成的参数化计算图。数据管道将原始数据提取和转换为DNN所需的输入格式。训练机制涉及识别产生可接受功能的参数（权重）。本节还提到了训练效率的优化，例如高效的数据管道操作和根据训练设备调整超参数。</li>
</ul>
</li>
</ul>
<p><img src="/.io//image-20230813175437332.png" alt="image-20230813175437332"></p>
<h3 id="三类DNN重用："><a href="#三类DNN重用：" class="headerlink" title="三类DNN重用："></a>三类DNN重用：</h3><p><img src="/.io//image-20230813155225994.png" alt="image-20230813155225994"></p>
<h4 id="Challenge-in-Conceptual-Reuse（概念重用）"><a href="#Challenge-in-Conceptual-Reuse（概念重用）" class="headerlink" title="Challenge in Conceptual Reuse（概念重用）"></a>Challenge in Conceptual Reuse（概念重用）</h4><ul>
<li>reproducing results using the same code and dataset</li>
</ul>
<p>可重复性差，文档缺失，测试不严格，缺乏可移植性考虑等</p>
<ul>
<li>replication and model reengineering</li>
</ul>
<p>model operationalization, portability of DL operations, and performance debugging. (模型操作化、DL操作的可移植性和性能调试)</p>
<h4 id="Challenges-in-Adaptation-Reuse-of-DNNs（适应性重用）"><a href="#Challenges-in-Adaptation-Reuse-of-DNNs（适应性重用）" class="headerlink" title="Challenges in Adaptation Reuse of DNNs（适应性重用）"></a>Challenges in Adaptation Reuse of DNNs（适应性重用）</h4><p>如Hugging Face通常缺少软件质量的DNN信息，如模型来源、再现性和可移植性，以及流行度、质量和维护等传统软件信息。</p>
<p>DNN重用的4种攻击：Train-Time Attacks、Idle-Time Attacks、Inference-Time Attacks、Traditional Supply Chain Attacks。</p>
<p><a target="_blank" rel="noopener" href="https://karpathy.medium.com/software-2-0-a64152b37c35">https://karpathy.medium.com/software-2-0-a64152b37c35</a></p>
<h4 id="Challenges-in-Deployment-Reuse-of-DNNs（部署重用）"><a href="#Challenges-in-Deployment-Reuse-of-DNNs（部署重用）" class="headerlink" title="Challenges in Deployment Reuse of DNNs（部署重用）"></a>Challenges in Deployment Reuse of DNNs（部署重用）</h4><p>每太看懂？和TVM有关</p>
<h4 id="供应链安全："><a href="#供应链安全：" class="headerlink" title="供应链安全："></a>供应链安全：</h4><p>Supply Chain Security for DNNs: The software engineering community has been working on systems such as TUF [124] and Sigstore [108] to increase the usability and effectiveness of signatures for package managers. The community has also began to develop standards such as Supply-chain Levels for Software Artifacts (SLSA) [125] and Software Supply Chain Best Practices from the Cloud Native Computing Foundation (CNCF) [126] to help engineers implement appropriate supply chain security measures. Similar efforts should be taken to create systems and standards for the DNN community, e.g., determining which concepts still apply to DNN environments and which concepts need to be changed. For example, Figure 7 shows how traditional signing methods may be inadequate in DNN supply chains. Future work could consider how to preserve the relationship between a particular DNN and the dataset(s) it was trained on. This might be accomplished by watermarking [127] or some form of limited reproduction, whereby users validate model-dataset relationships via retraining.</p>
<p>dnn的供应链安全:软件工程社区一直致力于像TUF[124]和Sigstore[108]这样的系统，以提高包管理器签名的可用性和有效性。社区还开始制定标准，如软件工件的供应链级别(SLSA)[125]和云原生计算基金会(CNCF)的软件供应链最佳实践[126]，以帮助工程师实施适当的供应链安全措施。应该采取类似的努力为深度神经网络社区创建系统和标准，例如，确定哪些概念仍然适用于深度神经网络环境，哪些概念需要改变。例如，图7显示了传统的签名方法在DNN供应链中是如何不足的。未来的工作可以考虑如何保持特定DNN和它所训练的数据集之间的关系。这可以通过水印[127]或某种形式的有限复制来实现，用户通过再训练来验证模型-数据集的关系。</p>
<h2 id="Discrepancies-among-Pre-trained-Deep-Neural-Networks-A-New-Threat-to-Model-Zoo-Reliability（Proceedings-of-the-30th-ACM-Joint-European-Software-Engineering-Conference-…-2022）"><a href="#Discrepancies-among-Pre-trained-Deep-Neural-Networks-A-New-Threat-to-Model-Zoo-Reliability（Proceedings-of-the-30th-ACM-Joint-European-Software-Engineering-Conference-…-2022）" class="headerlink" title="Discrepancies among Pre-trained Deep Neural Networks:A New Threat to Model Zoo Reliability（Proceedings of the 30th ACM Joint European Software Engineering Conference …, 2022）"></a>Discrepancies among Pre-trained Deep Neural Networks:A New Threat to Model Zoo Reliability（Proceedings of the 30th ACM Joint European Software Engineering Conference …, 2022）</h2><h3 id="论文简要-2"><a href="#论文简要-2" class="headerlink" title="论文简要 :"></a>论文简要 :</h3><ul>
<li>本研究发现了预训练深度神经网络（PTNNs）在模型动物园中存在的差异，这对模型动物园的可靠性构成了新的威胁。通过测量36个PTNNs在四个模型动物园中的准确性、延迟和架构等方面的差异，我们发现了一些显著的差异。这些发现呼吁进一步研究关于模型动物园的实证验证、自动化测量工具和最佳实践的工作。</li>
</ul>
<p>A <strong>model zoo</strong> is a collection of PTNNs for various tasks.</p>
<h3 id="背景信息-3"><a href="#背景信息-3" class="headerlink" title="背景信息:"></a>背景信息:</h3><ul>
<li>论文背景: 随着训练深度神经网络（DNNs）所需的时间和资源的增加，使用预训练深度神经网络（PTNNs）从模型动物园中获取已训练好的模型成为一种快速部署的实践方法。然而，模型动物园的可靠性尚未得到验证。在缺乏关于PTNNs实现和性能的行业标准的情况下，工程师无法自信地将其纳入生产系统。因此，本研究旨在发现模型动物园中PTNNs之间的潜在差异，以揭示模型动物园可靠性的威胁。</li>
<li>过去方案: 过去的研究表明，深度学习系统在准确性方面存在差异。然而，对于模型动物园中PTNNs的更广泛的可靠性度量尚未得到探索。本研究通过测量36个PTNNs在四个模型动物园中的准确性、延迟和架构等方面的差异，发现了一些显著的差异。</li>
<li>论文的Motivation: 本研究的动机在于探索模型动物园的可靠性。通过测量不同模型动物园中PTNNs的差异，我们可以发现准确性、延迟和架构等方面的问题，从而引发对模型动物园可靠性的关注。这些发现将为未来的研究提供启示，包括实证验证、自动化测量工具和模型动物园实现的最佳实践。</li>
</ul>
<h3 id="方法-1"><a href="#方法-1" class="headerlink" title="方法:"></a>方法:</h3><ul>
<li>a. 理论背景:<ul>
<li>本文介绍了预训练深度神经网络（PTNNs）在模型动物园中的使用，以加快部署速度。然而，模型动物园的可靠性尚未得到验证，可能导致PTNNs的准确性、延迟和架构存在差异。本研究旨在测量这些差异，并呼吁未来研究进行经验证实、自动化测量工具和最佳实践的实施。</li>
</ul>
</li>
<li>b. 技术路线:<ul>
<li>本文首先介绍了PTNNs在各个领域的应用以及提高工程师生产力的最佳实践需求。其次，提到了复制和发布高质量PTNNs的挑战，以及模型动物园可靠性的缺乏验证。文章强调了影响DNNs准确性复制的非确定性因素以及与深度学习框架相关的性能差异。强调了在不同模型动物园中测量PTNNs差异的需求。</li>
</ul>
</li>
</ul>
<h2 id="BadNets-Identifying-Vulnerabilities-in-the-Machine-Learning-Model-Supply-Chain（arXiv-preprint-arXiv-1708-06733-2017）"><a href="#BadNets-Identifying-Vulnerabilities-in-the-Machine-Learning-Model-Supply-Chain（arXiv-preprint-arXiv-1708-06733-2017）" class="headerlink" title="BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain（arXiv preprint arXiv:1708.06733, 2017）"></a>BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain（arXiv preprint arXiv:1708.06733, 2017）</h2><h3 id="方法-2"><a href="#方法-2" class="headerlink" title="方法:"></a>方法:</h3><ul>
<li>a. 理论背景:<ul>
<li>本文描述了深度神经网络（DNN）及其训练过程，以及迁移学习（transfer learning）技术，该技术允许使用预训练模型进行相关任务，减少计算成本。</li>
</ul>
</li>
<li>b. 技术路线:<ul>
<li>本文讨论了两种攻击场景：外包训练和迁移学习攻击，攻击者旨在创建一个带有后门的模型，该模型在验证集上保持高准确性，但在具有攻击者选择属性的输入上产生错误结果。攻击者可以使用各种技术，如修改训练数据集或手动设置返回的网络参数。</li>
</ul>
</li>
</ul>
<h3 id="结果"><a href="#结果" class="headerlink" title="结果:"></a>结果:</h3><ul>
<li>a. 详细的实验设置:<ul>
<li>本文实现了针对MNIST数字识别任务和交通标志检测的恶意训练卷积神经网络（BadNets），并证明了BadNets可以通过贴上便利贴的方式在真实世界图像上将停止标志恶意错误分类为限速标志。即使将BadNets下载并适应于新的机器学习任务，后门仍然存在，导致新任务的分类准确性显著下降。还评估了Caffe Model Zoo的安全性，该库是流行的预训练CNN模型的来源，发现了引入带有后门模型的几个入口点。作者建议从可信的来源获取预训练模型，并通过提供传输完整性的渠道进行传输，并要求存储库对模型使用数字签名。</li>
</ul>
</li>
<li>b. 详细的实验结果:<ul>
<li>本文呼吁研究检测深度神经网络中后门的技术，以应对外包训练和迁移学习攻击引入的安全问题。</li>
</ul>
</li>
</ul>
<h2 id="An-Empirical-Study-of-Artifacts-and-Security-Risks-in-the-Pre-trained-Model-Supply-Chain（Proceedings-of-the-2022-ACM-Workshop-on-Software-Supply-Chain-Offensive-…-2022）"><a href="#An-Empirical-Study-of-Artifacts-and-Security-Risks-in-the-Pre-trained-Model-Supply-Chain（Proceedings-of-the-2022-ACM-Workshop-on-Software-Supply-Chain-Offensive-…-2022）" class="headerlink" title="An Empirical Study of Artifacts and Security Risks in the Pre-trained Model Supply Chain（Proceedings of the 2022 ACM Workshop on Software Supply Chain Offensive …, 2022）"></a>An Empirical Study of Artifacts and Security Risks in the Pre-trained Model Supply Chain（Proceedings of the 2022 ACM Workshop on Software Supply Chain Offensive …, 2022）</h2><h3 id="论文简要-3"><a href="#论文简要-3" class="headerlink" title="论文简要 :"></a>论文简要 :</h3><ul>
<li>本研究通过实证研究了预训练模型供应链中的工件和安全风险，发现现有的防御措施不足以确保预训练模型的安全性，并提出了进一步的测量和工具方向，以增加预训练模型供应链的可靠性。</li>
</ul>
<h3 id="背景信息-4"><a href="#背景信息-4" class="headerlink" title="背景信息:"></a>背景信息:</h3><ul>
<li>论文背景: 深度神经网络在许多任务上取得了最先进的性能，但需要越来越复杂的架构和昂贵的训练过程。为了降低成本，工程师可以重复使用预训练模型（PTM）并对其进行微调以适应自己的任务。然而，尽管模型集线器现在在流行度和规模上与其他软件生态系统相当，但与之相关的PTM供应链尚未从软件工程的角度进行研究。</li>
<li>过去方案: 过去的研究已经研究了传统软件注册表中的安全风险，但尚未对PTM供应链进行系统调查。此外，机器学习社区已经研究了对DNN和PTM的敌对攻击。本研究综合了传统软件生态系统安全研究和深度学习攻击技术，以了解PTM供应链的风险。</li>
<li>论文的Motivation: 本研究的动机是为了填补预训练模型供应链的研究空白，并揭示其中的工件和安全风险。通过实证研究，作者希望了解不同类型的模型集线器之间的相似性和差异性，并提出进一步的测量和工具方向，以提高PTM供应链的可靠性。</li>
</ul>
<h3 id="方法-3"><a href="#方法-3" class="headerlink" title="方法:"></a>方法:</h3><ul>
<li>a. 理论背景:<ul>
<li>本研究通过实证调查分析了预训练模型（PTM）供应链中的工件和安全风险。研究人员分析了8个模型中心，并确定了潜在的威胁模型，强调了现有防御措施在确保PTM安全方面的不足。他们将PTM供应链与传统供应链进行了比较，并提出了进一步的测量和工具方向，以增强PTM供应链的可靠性。</li>
</ul>
</li>
<li>b. 技术路线:<ul>
<li>本研究通过对8个模型中心进行实证研究，对PTM供应链进行了表征。研究人员确定了三种类型的模型中心（开放型、门控型和商业型），其安全性质各不相同。该研究还将PTM供应链中的版本控制和安全风险与传统供应链进行了比较。</li>
</ul>
</li>
</ul>
<h3 id="结果-1"><a href="#结果-1" class="headerlink" title="结果:"></a>结果:</h3><ul>
<li>a. 详细的实验设置:<ul>
<li>本研究分析了8个不同的深度学习模型中心，包括Hugging Face、TensorFlow Hub、Pytorch Hub、MATLAB Model Hub、ONNX Model Zoo、NVIDIA NGC、Modelhub和model zoo。这些模型中心托管了各种工件，如模型、数据集和其他资源，作为研究到实践的管道。模型中心的属性和工件因其类型而异。</li>
</ul>
</li>
<li>b. 详细的实验结果:<ul>
<li>本研究的贡献包括测量8个模型中心的工件，确定它们的典型结构，并描述PTM供应链。研究人员还指出了不同模型中心的安全特性，并总结了威胁模型。此外，他们还强调了PTM供应链与传统供应链之间版本控制和安全风险的差异。</li>
</ul>
</li>
</ul>
<p>Security Feature in Open Model Hubs</p>
<p>从内部因素和外部因素分析了Open Model Hubs的威胁</p>
<p>内部：没有文件校验矫正等机制，恶意员工可以访问中心服务器修改</p>
<p>外部：恶意更改模型数据产生威胁模型、模型窃取</p>
</article><!-- lincense--><div class="license-wrapper"><p> <span>Author:  </span><a href="https://mospic.github.io">Mospic</a></p><p> <span>Link:  </span><a href="https://mospic.github.io/2023/08/14/AI-security-supply-chain/">https://mospic.github.io/2023/08/14/AI-security-supply-chain/</a></p><p> <span>Copyright:  </span><span>All articles in this blog are licensed under <a rel="license noopener" target="_blank" href="https://creativecommons.org/licenses/by-nc-nd/3.0">CC BY-NC-SA 3.0</a> unless stating additionally.</span></p></div><div class="post-paginator"><a class="nextSlogan" href="/2023/07/30/My-extension-for-Oyente-Supporting-more-versions-of-solidity/" title="My extension for Oyente:Supporting more versions of solidity"><span>NextPost ></span><br><span class="nextTitle">My extension for Oyente:Supporting more versions of solidity</span></a><div class="clear"></div></div><div id="comment"></div></section></article><footer id="cxo-footer-outer"><div id="cxo-footer-inner"><p class="footer-container"><span>Site by </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span> | theme </span><a target="_blank" rel="noopener" href="https://github.com/Longlongyu/hexo-theme-Cxo"><span>Cxo</span></a></p><i class="fa fa-user"> </i><span id="busuanzi_value_site_uv"></span><span> | </span><i class="fa fa-eye"> </i><span id="busuanzi_value_site_pv"></span></div></footer><!-- catelog--><div class="toc-wrapper" style="top: 70vh;"><div class="toc-catalog"><i class="fa fa-list"> </i><span>CATALOG</span></div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#AI%E8%BD%AF%E4%BB%B6%E4%BE%9B%E5%BA%94%E9%93%BE%E5%AE%89%E5%85%A8"><span class="toc-number">1.</span> <span class="toc-text">AI软件供应链安全</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BD%AF%E4%BB%B6%E4%BE%9B%E5%BA%94%E9%93%BE"><span class="toc-number">1.1.</span> <span class="toc-text">软件供应链</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#AI%E8%BD%AF%E4%BB%B6%E9%87%8D%E7%94%A8%E5%A8%81%E8%83%81"><span class="toc-number">1.2.</span> <span class="toc-text">AI软件重用威胁</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Model-Reuse-Attacks-on-Deep-Learning-Systems%EF%BC%88Proceedings-of-the-2018-ACM-SIGSAC-conference-on-computer-and-communications-%E2%80%A6-2018%EF%BC%89"><span class="toc-number">1.2.1.</span> <span class="toc-text">Model-Reuse Attacks on Deep Learning Systems（Proceedings of the 2018 ACM SIGSAC conference on computer and communications …, 2018）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%83%8C%E6%99%AF%E4%BF%A1%E6%81%AF"><span class="toc-number">1.2.1.1.</span> <span class="toc-text">背景信息:</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8E%9F%E5%A7%8B%E6%A8%A1%E5%9E%8B%E5%9C%A8GitHub%E4%B8%AD%E7%9A%84%E9%87%8D%E7%94%A8"><span class="toc-number">1.2.1.2.</span> <span class="toc-text">原始模型在GitHub中的重用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%87%8D%E7%94%A8%E5%8F%AF%E8%83%BD%E9%80%A0%E6%88%90%E7%9A%84%E6%94%BB%E5%87%BB%E5%BD%B1%E5%93%8D"><span class="toc-number">1.2.1.3.</span> <span class="toc-text">重用可能造成的攻击影响</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%8E%E9%9D%A2%E6%90%9E%E4%BA%86%E4%B8%80%E5%A0%86%E5%85%AC%E5%BC%8F%E5%92%8C%E7%AE%97%E6%B3%95"><span class="toc-number">1.2.1.4.</span> <span class="toc-text">后面搞了一堆公式和算法</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#An-Empirical-Study-of-Pre-Trained-Model-Reuse-in-the-Hugging-Face-Deep-Learning-Model-Registry%EF%BC%88arXiv-preprint-arXiv-2303-02552-2023%EF%BC%89"><span class="toc-number">1.3.</span> <span class="toc-text">An Empirical Study of Pre-Trained Model Reuse in the Hugging Face Deep Learning Model Registry（arXiv preprint arXiv:2303.02552, 2023）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%BA%E6%96%87%E7%AE%80%E8%A6%81"><span class="toc-number">1.3.1.</span> <span class="toc-text">论文简要 :</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%83%8C%E6%99%AF%E4%BF%A1%E6%81%AF-1"><span class="toc-number">1.3.2.</span> <span class="toc-text">背景信息:</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%84%8F%E4%B9%89"><span class="toc-number">1.3.3.</span> <span class="toc-text">意义:</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B3%E6%B3%A8PTM%E9%87%8D%E7%94%A8%EF%BC%9A"><span class="toc-number">1.3.4.</span> <span class="toc-text">关注PTM重用：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reusing-Deep-Learning-Models-Challenges-and-Directions-in-Software-Engineering%EF%BC%88arXiv-preprint-arXiv-2303-07476-2023%EF%BC%89"><span class="toc-number">1.4.</span> <span class="toc-text">Reusing Deep Learning Models: Challenges and Directions in Software Engineering（arXiv preprint arXiv:2303.07476, 2023）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%BA%E6%96%87%E7%AE%80%E8%A6%81-1"><span class="toc-number">1.4.1.</span> <span class="toc-text">论文简要 :</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%83%8C%E6%99%AF%E4%BF%A1%E6%81%AF-2"><span class="toc-number">1.4.2.</span> <span class="toc-text">背景信息:</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E6%B3%95"><span class="toc-number">1.4.3.</span> <span class="toc-text">方法:</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E7%B1%BBDNN%E9%87%8D%E7%94%A8%EF%BC%9A"><span class="toc-number">1.4.4.</span> <span class="toc-text">三类DNN重用：</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Challenge-in-Conceptual-Reuse%EF%BC%88%E6%A6%82%E5%BF%B5%E9%87%8D%E7%94%A8%EF%BC%89"><span class="toc-number">1.4.4.1.</span> <span class="toc-text">Challenge in Conceptual Reuse（概念重用）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Challenges-in-Adaptation-Reuse-of-DNNs%EF%BC%88%E9%80%82%E5%BA%94%E6%80%A7%E9%87%8D%E7%94%A8%EF%BC%89"><span class="toc-number">1.4.4.2.</span> <span class="toc-text">Challenges in Adaptation Reuse of DNNs（适应性重用）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Challenges-in-Deployment-Reuse-of-DNNs%EF%BC%88%E9%83%A8%E7%BD%B2%E9%87%8D%E7%94%A8%EF%BC%89"><span class="toc-number">1.4.4.3.</span> <span class="toc-text">Challenges in Deployment Reuse of DNNs（部署重用）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BE%9B%E5%BA%94%E9%93%BE%E5%AE%89%E5%85%A8%EF%BC%9A"><span class="toc-number">1.4.4.4.</span> <span class="toc-text">供应链安全：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Discrepancies-among-Pre-trained-Deep-Neural-Networks-A-New-Threat-to-Model-Zoo-Reliability%EF%BC%88Proceedings-of-the-30th-ACM-Joint-European-Software-Engineering-Conference-%E2%80%A6-2022%EF%BC%89"><span class="toc-number">1.5.</span> <span class="toc-text">Discrepancies among Pre-trained Deep Neural Networks:A New Threat to Model Zoo Reliability（Proceedings of the 30th ACM Joint European Software Engineering Conference …, 2022）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%BA%E6%96%87%E7%AE%80%E8%A6%81-2"><span class="toc-number">1.5.1.</span> <span class="toc-text">论文简要 :</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%83%8C%E6%99%AF%E4%BF%A1%E6%81%AF-3"><span class="toc-number">1.5.2.</span> <span class="toc-text">背景信息:</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E6%B3%95-1"><span class="toc-number">1.5.3.</span> <span class="toc-text">方法:</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#BadNets-Identifying-Vulnerabilities-in-the-Machine-Learning-Model-Supply-Chain%EF%BC%88arXiv-preprint-arXiv-1708-06733-2017%EF%BC%89"><span class="toc-number">1.6.</span> <span class="toc-text">BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain（arXiv preprint arXiv:1708.06733, 2017）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E6%B3%95-2"><span class="toc-number">1.6.1.</span> <span class="toc-text">方法:</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E6%9E%9C"><span class="toc-number">1.6.2.</span> <span class="toc-text">结果:</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#An-Empirical-Study-of-Artifacts-and-Security-Risks-in-the-Pre-trained-Model-Supply-Chain%EF%BC%88Proceedings-of-the-2022-ACM-Workshop-on-Software-Supply-Chain-Offensive-%E2%80%A6-2022%EF%BC%89"><span class="toc-number">1.7.</span> <span class="toc-text">An Empirical Study of Artifacts and Security Risks in the Pre-trained Model Supply Chain（Proceedings of the 2022 ACM Workshop on Software Supply Chain Offensive …, 2022）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%BA%E6%96%87%E7%AE%80%E8%A6%81-3"><span class="toc-number">1.7.1.</span> <span class="toc-text">论文简要 :</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%83%8C%E6%99%AF%E4%BF%A1%E6%81%AF-4"><span class="toc-number">1.7.2.</span> <span class="toc-text">背景信息:</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E6%B3%95-3"><span class="toc-number">1.7.3.</span> <span class="toc-text">方法:</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E6%9E%9C-1"><span class="toc-number">1.7.4.</span> <span class="toc-text">结果:</span></a></li></ol></li></ol></li></ol></div><!-- top--><i class="fa fa-arrow-up close" id="go-up" aria-hidden="true"></i></body></html>